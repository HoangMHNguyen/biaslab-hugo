<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting started · ForneyLab.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><nav class="toc"><a href="../index.html"><img class="logo" src="../assets/logo.png" alt="ForneyLab.jl logo"/></a><h1>ForneyLab.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li class="current"><a class="toctext" href>Getting started</a><ul class="internal"><li><a class="toctext" href="#Installation-1">Installation</a></li><li><a class="toctext" href="#Example:-Inferring-the-bias-of-a-coin-1">Example: Inferring the bias of a coin</a></li><li><a class="toctext" href="#Where-to-go-next?-1">Where to go next?</a></li></ul></li><li><a class="toctext" href="../user-guide/">User guide</a></li><li><span class="toctext">Library</span><ul><li><a class="toctext" href="../library/public-api/">Public API</a></li><li><a class="toctext" href="../library/internal-api/">Internal API</a></li></ul></li><li><a class="toctext" href="../contributing/">Contributing</a></li><li><a class="toctext" href="../internals/">Internals</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Getting started</a></li></ul><a class="edit-page" href="https://github.com/biaslab/ForneyLab.jl/blob/master/docs/src/getting-started.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Getting started</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Getting-started-1" href="#Getting-started-1">Getting started</a></h1><p>This page provides the necessary information you need to get started with ForneyLab. We will show the general approach to solving inference problems with ForneyLab by means of a running example: Inferring the bias of a coin.</p><h2><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h2><p>Install ForneyLab through the Julia package manager:</p><pre><code class="language-julia">] add ForneyLab</code></pre><div class="admonition note"><div class="admonition-title">Note</div><div class="admonition-text"><p>If you want to use the graph visualization functions, you need to have <a href="http://www.graphviz.org/">GraphViz</a> installed.</p></div></div><h2><a class="nav-anchor" id="Example:-Inferring-the-bias-of-a-coin-1" href="#Example:-Inferring-the-bias-of-a-coin-1">Example: Inferring the bias of a coin</a></h2><p>The ForneyLab approach to solving inference problems consists of three phases:</p><ol><li><a href="#getting-started-model-specification-1">Model specification</a>: ForneyLab provides a simple metalanguage to specify probabilistic models.</li><li><a href="#Message-passing-algorithm-generation-1">Message-passing algorithm generation</a>: Given a model, it is ForneyLab&#39;s job to provide you with an algorithm that runs inference on your quantities of interest.</li><li><a href="#Message-passing-inference-execution-1">Message-passing inference execution</a>: Feed observations and a prior belief over your quantities of interest to the algorithm and you will get an updated posterior in return.</li></ol><h3><a class="nav-anchor" id="Coin-flip-simulation-1" href="#Coin-flip-simulation-1">Coin flip simulation</a></h3><p>Let&#39;s start by gathering some data. One approach could be flipping a coin N times and recording each outcome. Here, however, we will simulate this process by sampling some values from a Bernoulli distribution. Each sample can be thought of as the outcome of single flip which is either heads or tails (1 or 0). We will assume that our virtual coin has an underlying probability of 75% of landing heads up.</p><pre><code class="language-julia">N = 25          # number of coin tosses
p = 0.75        # p parameter of the Bernoulli distribution
sbernoulli(n, p) = [(rand() &lt; p) ? 1 : 0 for _ = 1:n] # define Bernoulli sampler
dataset = sbernoulli(N, p); # run N Bernoulli trials
print(&quot;dataset = &quot;) ; show(dataset)</code></pre><pre><code class="language-none">dataset = [1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0]</code></pre><h3><a class="nav-anchor" id="getting-started-model-specification-1" href="#getting-started-model-specification-1">Model specification</a></h3><p>In a Bayesian setting, the next step is to specify our probabilistic model. This amounts to specifying the joint probability of the random variables of the system.</p><h4><a class="nav-anchor" id="Likelihood-1" href="#Likelihood-1">Likelihood</a></h4><p>We will assume that the outcome of each coin flip is governed by the Bernoulli distribution, i.e.</p><p><span>$y_i \sim Bernoulli(\theta)$</span>,</p><p>where <span>$y_i=1$</span> represents &quot;heads&quot;, <span>$y_i=0$</span> represents &quot;tails&quot;, and <span>$θ \in [0,1]$</span> is the underlying probability of the coin landing heads up for a single coin flip.</p><h4><a class="nav-anchor" id="Prior-1" href="#Prior-1">Prior</a></h4><p>We will choose the conjugate prior of the Bernoulli likelihood function defined above, namely the beta distribution, i.e.</p><p><span>$\theta \sim Beta(a, b)$</span>,</p><p>where <span>$a$</span> and <span>$b$</span> are the hyperparameters that encode our prior beliefs about the possible values of <span>$\theta$</span>. We will assign values to the hyperparameters in a later step.   </p><h4><a class="nav-anchor" id="Joint-probability-1" href="#Joint-probability-1">Joint probability</a></h4><p>The joint probability is given by the multiplication of the likelihood and the prior, i.e.</p><p><span>$P(\{y_i\}, θ) = \prod_{i=1}^N P(\{y_i\} | θ) P(θ)$</span>.</p><p>Now let&#39;s see how to specify this model using ForneyLab&#39;s syntax.</p><div></div><pre><code class="language-julia">using ForneyLab
g = FactorGraph()       # create a factor graph
a = placeholder(:a)     # define hyperparameter a as placeholder
b = placeholder(:b)     # define hyperparameter b as placeholder
@RV θ ~ Beta(a, b)      # prior
@RV y ~ Bernoulli(θ)    # likelihood
placeholder(y, :y)      # define y as a placeholder for data
draw(g)                 # draw the factor graph</code></pre><?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.40.1 (20161225.0304)
 -->
<!-- Title: G Pages: 1 -->
<svg width="257pt" height="392pt"
 viewBox="0.00 0.00 256.72 392.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 388)">
<title>G</title>
<polygon fill="#ffffff" stroke="transparent" points="-4,4 -4,-388 252.7239,-388 252.7239,4 -4,4"/>
<!-- 8567329079539637594 -->
<g id="node1" class="node">
<title>8567329079539637594</title>
<polygon fill="none" stroke="#000000" points="160.2356,-170 88.2356,-170 88.2356,-98 160.2356,-98 160.2356,-170"/>
<text text-anchor="middle" x="124.2356" y="-135.8" font-family="Times,serif" font-size="9.00" fill="#000000">Beta</text>
<text text-anchor="middle" x="124.2356" y="-126.8" font-family="Times,serif" font-size="9.00" fill="#000000">beta_1</text>
</g>
<!-- 15178695350182574641 -->
<g id="node4" class="node">
<title>15178695350182574641</title>
<polygon fill="#d3d3d3" stroke="#000000" points="66.7085,-54 -.2373,-54 -.2373,0 66.7085,0 66.7085,-54"/>
<text text-anchor="middle" x="33.2356" y="-24.3" font-family="Times,serif" font-size="9.00" fill="#000000">placeholder_a</text>
</g>
<!-- 8567329079539637594&#45;&#45;15178695350182574641 -->
<g id="edge2" class="edge">
<title>8567329079539637594&#45;&#45;15178695350182574641</title>
<path fill="none" stroke="#000000" d="M88.1243,-101.0686C81.398,-94.3404 74.6246,-87.1307 68.6848,-80 62.0249,-72.0048 55.4764,-62.7352 49.8553,-54.2052"/>
<text text-anchor="start" x="69.2356" y="-73.6" font-family="Times,serif" font-size="8.00" fill="#ff0000">a</text>
<text text-anchor="start" x="31.6327" y="-55.8052" font-family="Times,serif" font-size="8.00" fill="#000000">1 out </text>
<text text-anchor="start" x="76.5735" y="-102.6686" font-family="Times,serif" font-size="8.00" fill="#000000">2 a </text>
</g>
<!-- 9100990654906240734 -->
<g id="node5" class="node">
<title>9100990654906240734</title>
<polygon fill="#d3d3d3" stroke="#000000" points="248.7122,-54 181.759,-54 181.759,0 248.7122,0 248.7122,-54"/>
<text text-anchor="middle" x="215.2356" y="-24.3" font-family="Times,serif" font-size="9.00" fill="#000000">placeholder_b</text>
</g>
<!-- 8567329079539637594&#45;&#45;9100990654906240734 -->
<g id="edge4" class="edge">
<title>8567329079539637594&#45;&#45;9100990654906240734</title>
<path fill="none" stroke="#000000" d="M155.044,-97.7747C167.2127,-83.4665 180.9519,-67.3116 192.2284,-54.0525"/>
<text text-anchor="start" x="175.2356" y="-73.6" font-family="Times,serif" font-size="8.00" fill="#ff0000">b</text>
<text text-anchor="start" x="174.0057" y="-55.6525" font-family="Times,serif" font-size="8.00" fill="#000000">1 out </text>
<text text-anchor="start" x="143.044" y="-91.3747" font-family="Times,serif" font-size="8.00" fill="#000000">3 b </text>
</g>
<!-- 8343489939835346800 -->
<g id="node2" class="node">
<title>8343489939835346800</title>
<polygon fill="none" stroke="#000000" points="160.2356,-286 88.2356,-286 88.2356,-214 160.2356,-214 160.2356,-286"/>
<text text-anchor="middle" x="124.2356" y="-251.8" font-family="Times,serif" font-size="9.00" fill="#000000">Ber</text>
<text text-anchor="middle" x="124.2356" y="-242.8" font-family="Times,serif" font-size="9.00" fill="#000000">bernoulli_1</text>
</g>
<!-- 8343489939835346800&#45;&#45;8567329079539637594 -->
<g id="edge3" class="edge">
<title>8343489939835346800&#45;&#45;8567329079539637594</title>
<path fill="none" stroke="#000000" d="M124.2356,-213.9327C124.2356,-199.9661 124.2356,-184.0095 124.2356,-170.045"/>
<text text-anchor="start" x="124.2356" y="-189.6" font-family="Times,serif" font-size="8.00" fill="#ff0000">θ</text>
<text text-anchor="start" x="106.0129" y="-171.645" font-family="Times,serif" font-size="8.00" fill="#000000">1 out </text>
<text text-anchor="start" x="112.2356" y="-207.5327" font-family="Times,serif" font-size="8.00" fill="#000000">2 p </text>
</g>
<!-- 10304862998478861339 -->
<g id="node3" class="node">
<title>10304862998478861339</title>
<polygon fill="#d3d3d3" stroke="#000000" points="157.7122,-384 90.759,-384 90.759,-330 157.7122,-330 157.7122,-384"/>
<text text-anchor="middle" x="124.2356" y="-354.3" font-family="Times,serif" font-size="9.00" fill="#000000">placeholder_y</text>
</g>
<!-- 10304862998478861339&#45;&#45;8343489939835346800 -->
<g id="edge1" class="edge">
<title>10304862998478861339&#45;&#45;8343489939835346800</title>
<path fill="none" stroke="#000000" d="M124.2356,-329.9994C124.2356,-316.7507 124.2356,-300.6013 124.2356,-286.2906"/>
<text text-anchor="start" x="124.2356" y="-305.6" font-family="Times,serif" font-size="8.00" fill="#ff0000">y</text>
<text text-anchor="start" x="106.0129" y="-287.8906" font-family="Times,serif" font-size="8.00" fill="#000000">1 out </text>
<text text-anchor="start" x="106.0129" y="-323.5994" font-family="Times,serif" font-size="8.00" fill="#000000">1 out </text>
</g>
</g>
</svg>
<p>As you can see, ForneyLab offers a model specification syntax that resembles closely to the mathematical equations defined above. Placeholders are used to indicate variables that take specific values at a later date. For example, the way we feed observations into the model is by iteratively assigning each of the observations in our dataset to the random variable <code>y</code>. Perhaps less obvious is the fact that the hyperparameters <code>a</code> and <code>b</code> are also defined as placeholders. The reason is that we will use them to input our current belief about <code>θ</code> for every observation that is processed. In section <a href="#Message-passing-inference-execution-1">Message-passing inference execution</a> we will see how this is done.</p><h3><a class="nav-anchor" id="Message-passing-algorithm-generation-1" href="#Message-passing-algorithm-generation-1">Message-passing algorithm generation</a></h3><p>Once we have defined our model, the next step is to instruct ForneyLab to generate a message-passing algorithm that solves our given inference problem. To do this, we need to specify which type of algorithm we want to use. In this case we will use <em>belief propagation</em>, also known as the <em>sum-product algorithm</em>. Once we execute the following code, we see that a function called <code>step!(...)</code> becomes available in the current scope. This function contains the sum-product message-passing algorithm.</p><pre><code class="language-julia"># Generate a message passging sum-product algorithm that infers theta
algo_str = sumProductAlgorithm(θ) # ForneyLab returns the algorithm as a string
algorithm = Meta.parse(algo_str) # parse the algorithm into a Julia expression
eval(algorithm); # evaluate the functions contained in the Julia expression</code></pre><pre><code class="language-julia">:(function step!(data::Dict, marginals::Dict=Dict(), messages::Vector{Message}=Array{Message}(undef, 2))
      #= none:3 =#
      messages[1] = ruleSPBetaOutVPP(nothing, Message(Univariate, PointMass, m=data[:a]), Message(Univariate, PointMass, m=data[:b]))
      #= none:4 =#
      messages[2] = ruleSPBernoulliIn1PV(Message(Univariate, PointMass, m=data[:y]), nothing)
      #= none:6 =#
      marginals[:θ] = (messages[1]).dist * (messages[2]).dist
      #= none:8 =#
      return marginals
  end)</code></pre><h3><a class="nav-anchor" id="Message-passing-inference-execution-1" href="#Message-passing-inference-execution-1">Message-passing inference execution</a></h3><p>The last step is to execute the message-passing algorithm. In order to do this, we first need to assign values to the hyperparameters <span>$a$</span> and <span>$b$</span> which characterize our prior beliefs <span>$p(\theta)$</span> about the bias of the coin. Then, we need to feed the observations, one at a time, to the algorithm together with our current belief (prior) <span>$p(\theta)$</span> about the bias of the coin. The important thing to note here is that the posterior distribution after processing one observation <span>$p(\theta|y_{i-1})$</span> becomes the prior for the processing of the next observation.</p><pre><code class="language-julia"># Create a marginals dictionary, and initialize hyperparameters
a = 2.0
b = 7.0
marginals = Dict(:θ =&gt; ProbabilityDistribution(Beta, a=a, b=b))

for i in 1:N
    # Feed in datapoints 1 at a time
    data = Dict(:y =&gt; dataset[i],
                :a =&gt; marginals[:θ].params[:a],
                :b =&gt; marginals[:θ].params[:b])

    step!(data, marginals)
end</code></pre><h3><a class="nav-anchor" id="Results-1" href="#Results-1">Results</a></h3><p>The plot below shows the result of the inference procedure. We see how the posterior is a “compromise” between the prior and likelihood, as mandated by Bayesian inference.</p><pre><code class="language-">using Plots, LaTeXStrings, SpecialFunctions; theme(:default)
pyplot(fillalpha=0.3, leg=false, xlabel=L&quot;\theta&quot;, yticks=nothing)
BetaPDF(α, β) = x -&gt;  x^(α-1)*(1-x)^(β-1)/beta(α, β) # beta distribution definition
BernoulliPDF(z, N) = θ -&gt; θ^z*(1-θ)^(N-z) # Bernoulli distribution definition

rθ = range(0, 1, length=100)
p1 = plot(rθ, BetaPDF(a, b), title=&quot;Prior&quot;, fill=true, ylabel=L&quot;P(\theta)&quot;, c=1,)
p2 = plot(rθ, BernoulliPDF(sum(dataset), N), title=&quot;Likelihood&quot;, fill=true, ylabel=L&quot;P(D|\theta)&quot;, c=2)
p3 = plot(rθ, BetaPDF(marginals[:θ].params[:a], marginals[:θ].params[:b]), title=&quot;Posterior&quot;, fill=true, ylabel=L&quot;P(\theta|D)&quot;, c=3)
plot(p1, p2, p3, layout=@layout([a; b; c]))</code></pre><h2><a class="nav-anchor" id="Where-to-go-next?-1" href="#Where-to-go-next?-1">Where to go next?</a></h2><p>There are a set of <a href="https://github.com/biaslab/ForneyLab.jl/tree/master/demo">demos</a> available in ForneyLab&#39;s repository that demonstrate the more advanced features of ForneyLab. Alternatively, you can head to the <a href="../user-guide/#User-guide-1">User guide</a> which provides more detailed information of how to use ForneyLab to solve inference problems.</p><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="../user-guide/"><span class="direction">Next</span><span class="title">User guide</span></a></footer></article></body></html>
